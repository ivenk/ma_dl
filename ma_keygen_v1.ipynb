{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ivenk/ma_dl/blob/master/ma_keygen_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMYa4uiXAr8u"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbISke8Nigd4"
   },
   "outputs": [],
   "source": [
    "class MultiClass(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, input_dim=512, hidden_layers=5, output_dim=128):\n",
    "        super(MultiClass, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim, input_dim)\n",
    "        self.l2 = nn.Linear(input_dim, input_dim)\n",
    "        self.l3 = nn.Linear(input_dim, input_dim)\n",
    "        self.l4 = nn.Linear(input_dim, input_dim)\n",
    "        self.l5 = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "\n",
    " #   def classifier(self,z):\n",
    "  #      return nn.functional.softmax(self(z))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))       \n",
    "        x = F.relu(self.l4(x))\n",
    "        x = F.relu(self.l5(x))\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFolderDataset(Dataset):\n",
    "    def __init__(self, path_img_folder, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(path_img_folder, transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCSVDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path_img_folder, path_to_csv, transform=None):\n",
    "        self.meta_data = pd.read_csv(path_to_csv, sep=';')\n",
    "        self.path_img_folder = path_img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name, labels, validation = self.meta_data.iloc[index]\n",
    "        img = Image.open(self.path_img_folder + '/' + name + '.png')\n",
    "\n",
    "        labels = labels#.split(sep=\" \")\n",
    "        print(labels)\n",
    "        sample = { 'image' : img, 'labels' : labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image']= self.transform(sample['image'].convert(\"RGB\"))\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kOAf8JycQKI"
   },
   "outputs": [],
   "source": [
    "model = MultiClass()\n",
    "#model.cuda()\n",
    "#dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afcZ0oXZK7W-"
   },
   "outputs": [],
   "source": [
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    scaler, \n",
    "    to_tensor,\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "#dataset = CustomDataset('../../data/lfw.mini.list.out', '../../data/labels.csv', transform=transform)\n",
    "dataset = datasets.ImageFolder('../../data/lfw.mini.out/train', transform=transform)\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = datasets.ImageFolder('../../data/lfw.mini.out/valid', transform=transform)\n",
    "dataset_valid.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader_valid = DataLoader(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ds5xN3k9KqUk"
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "# Use the model object to select the desired layer\n",
    "layer = resnet._modules.get('avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o65tQEOVK3pV",
    "outputId": "761493a2-9ff3-4720-8632-e1906a3a4695"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwDMna7NLAUy"
   },
   "outputs": [],
   "source": [
    "def get_vector(img):\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))    \n",
    "    \n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)    \n",
    "\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "      my_embedding.copy_(o.data.squeeze())    \n",
    "    \n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)    \n",
    "    # 6. Run the model on our transformed image\n",
    "    resnet(t_img)    \n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()    \n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector2(img):\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(img)    \n",
    "    \n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)    #adjust for batch size here\n",
    "\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "      my_embedding.copy_(o.data.squeeze())    \n",
    "    \n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)    \n",
    "    # 6. Run the model on our transformed image\n",
    "    resnet(t_img)    \n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()    \n",
    "    \n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unQysse83RQZ"
   },
   "outputs": [],
   "source": [
    "def get_target_vector(target):\n",
    "    data = []\n",
    "\n",
    "    binary = f'{int(target):0128b}'\n",
    "    for c in binary:\n",
    "        data.append(int(c))\n",
    "\n",
    "    return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLAtJmz0LloS"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jEyTwBV1r-R"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.BCELoss() #MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) #weight_decay=1e-4 \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeCOs2fu1ETQ"
   },
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "# Adam optimizer with learning rate 0.1 and L2 regularization with weight 1e-4.\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1,weight_decay=1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mistakes(pred, target):\n",
    "    mistakes = 0\n",
    "    \n",
    "    if len(pred) != len(target):\n",
    "        raise Exception('sizes of both tensors must match')\n",
    "        \n",
    "    for x,y in zip(pred, target):\n",
    "        if round(x.item()) != y.item():\n",
    "            mistakes = mistakes + 1\n",
    "        \n",
    "    return mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarity: tensor([0.8081])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d,_ = dataset[0]\n",
    "a,_ = dataset[10]\n",
    "\n",
    "first_vector = get_vector2(d.unsqueeze(0))\n",
    "second_vector = get_vector2(a.unsqueeze(0))\n",
    "\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos_sim = cos(first_vector.unsqueeze(0),\n",
    "              second_vector.unsqueeze(0))\n",
    "\n",
    "print('\\nCosine similarity: {0}\\n'.format(cos_sim))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, name dim, torch.dtype dtype)\n * (Tensor input, int dim, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d7240fea38ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# zero grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b55cb50619c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, name dim, torch.dtype dtype)\n * (Tensor input, int dim, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    epoch_mistakes = 0\n",
    "    epoch_loss = 0\n",
    "    size = len(loader)\n",
    "    \n",
    "    for index, (data, target) in enumerate(loader):\n",
    "        data_t   = get_vector2(data)\n",
    "        \n",
    "        target_t = get_target_vector(dataset.idx_to_class[target[0].item()])        \n",
    "\n",
    "        data_v   = Variable(data_t, requires_grad=False)\n",
    "        target_v = Variable(target_t, requires_grad=False)\n",
    "\n",
    "        # forward\n",
    "        pred = model.forward(data_v)\n",
    "        # zero grads\n",
    "        optimizer.zero_grad()\n",
    "        # calculate loss\n",
    "        loss = loss_func(pred, target_v.float())\n",
    "        epoch_loss = epoch_loss + loss\n",
    "        # back prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_mistakes = epoch_mistakes + calculate_mistakes(pred, target_t)\n",
    "        \n",
    "        #print(str(index), end =\" \")\n",
    "        \n",
    "        \n",
    "    valid_loss = 0\n",
    "    valid_mistakes = 0\n",
    "    size_valid = len(loader_valid)\n",
    "    # do validation\n",
    "    for index, (data, target) in enumerate(loader_valid):\n",
    "        data_t   = get_vector2(data)\n",
    "        target_t = get_target_vector(dataset.idx_to_class[target[0].item()])\n",
    "\n",
    "        data_v   = Variable(data_t, requires_grad=False)\n",
    "        target_v = Variable(target_t, requires_grad=False)\n",
    "\n",
    "        # forward\n",
    "        pred = model.forward(data_v)\n",
    "        loss = loss_func(pred,target_v.float())\n",
    "        \n",
    "        valid_loss = valid_loss + loss\n",
    "        \n",
    "        valid_mistakes = valid_mistakes + calculate_mistakes(pred, target_t)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print('=============================')\n",
    "    print('epoch loss on training set: ' + str(epoch_loss))\n",
    "    print('epoch loss on validation set:' + str(valid_loss))\n",
    "    print('average mistakes on validation set: ' + str(valid_mistakes/size_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RzTZAz2PDrYY",
    "outputId": "ce33938b-8b33-4542-a07f-9319f36d18c7"
   },
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "  loss_epoch = 0\n",
    "  for index, (data,target) in enumerate(loader):\n",
    "\n",
    "    # prep\n",
    "    data_t   = get_vector(data)\n",
    "    target_t = get_target_vector(dataset.idx_to_class[target])\n",
    "\n",
    "    data_v   = Variable(data_t, requires_grad=False)\n",
    "    target_v = Variable(target_t, requires_grad=False)\n",
    "\n",
    "    # forward\n",
    "    pred = model.forward(data_v)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # calculate loss\n",
    "    \n",
    "    loss = loss_func(pred, target_v.float())\n",
    "    loss_epoch = loss_epoch + loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (index % 100) == 0:\n",
    "      print(str(index))\n",
    "\n",
    "  print(loss_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'save_v2_20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ma_keygen_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
